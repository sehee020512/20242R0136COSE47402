{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM6cQy2yAHqPa6PPrYSIxbK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sehee020512/20242R0136COSE47402/blob/master/final%20project%2012.3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "QoU1QQqgsdR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow\n",
        "!pip install transformers\n",
        "!pip install matplotlib\n",
        "!pip install timm"
      ],
      "metadata": {
        "id": "qXh8T6yA527A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4cc8b00-449e-4d87-a666-845eef1056c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.12)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.26.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import shutil\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "metadata": {
        "id": "mnufGblp5uub"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2dVkFJlielk",
        "outputId": "017f1927-6491-4f64-84bd-61da1c81d5f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/kavyasreeb/hair-type-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175M/175M [00:08<00:00, 20.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/kavyasreeb/hair-type-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"kavyasreeb/hair-type-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 데이터 경로\n",
        "source_path = \"/root/.cache/kagglehub/datasets/kavyasreeb/hair-type-dataset/versions/1\"\n",
        "\n",
        "# 복사할 대상 경로\n",
        "destination_path = \"/content/hair-type-dataset\"\n",
        "\n",
        "# 데이터 복사\n",
        "try:\n",
        "    shutil.copytree(source_path, destination_path)\n",
        "    print(f\"데이터가 {destination_path}에 복사되었습니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"복사 실패: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFi9T1TTzlJK",
        "outputId": "b1217eb9-ae88-41c9-a24a-d874b5802217"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터가 /content/hair-type-dataset에 복사되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 경로 설정\n",
        "dataset_dir = \"/content/hair-type-dataset/data\"  # 클래스별 이미지가 있는 디렉토리\n",
        "train_dir = \"/content/train\"  # train 데이터 저장 경로\n",
        "val_dir = \"/content/val\"  # validation 데이터 저장 경로\n",
        "test_dir = \"/content/test\"  # test 데이터 저장 경로\n",
        "\n",
        "# train/validation/test 디렉토리 생성\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# 이미지 확장자 필터\n",
        "valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
        "\n",
        "# 클래스별 train/validation/test 데이터 분리\n",
        "train_split_ratio = 0.7  # Train 70%\n",
        "val_split_ratio = 0.2    # Validation 20%\n",
        "test_split_ratio = 0.1   # Test 10%\n",
        "\n",
        "for category in os.listdir(dataset_dir):\n",
        "    category_path = os.path.join(dataset_dir, category)\n",
        "    if not os.path.isdir(category_path):\n",
        "        continue  # 디렉토리가 아니면 건너뜀\n",
        "\n",
        "    # 클래스별 이미지 파일 가져오기\n",
        "    images = [img for img in os.listdir(category_path) if img.lower().endswith(valid_extensions)]\n",
        "\n",
        "    # 이미지가 없으면 건너뜀\n",
        "    if len(images) == 0:\n",
        "        print(f\"'{category}' 폴더에 이미지가 없습니다. 건너뜁니다.\")\n",
        "        continue\n",
        "\n",
        "    # train/validation/test로 분리\n",
        "    train_images, temp_images = train_test_split(images, test_size=(1 - train_split_ratio), random_state=42)\n",
        "    val_images, test_images = train_test_split(temp_images, test_size=(test_split_ratio / (test_split_ratio + val_split_ratio)), random_state=42)\n",
        "\n",
        "    # 클래스별 train/validation/test 디렉토리 생성\n",
        "    train_category_dir = os.path.join(train_dir, category)\n",
        "    val_category_dir = os.path.join(val_dir, category)\n",
        "    test_category_dir = os.path.join(test_dir, category)\n",
        "    os.makedirs(train_category_dir, exist_ok=True)\n",
        "    os.makedirs(val_category_dir, exist_ok=True)\n",
        "    os.makedirs(test_category_dir, exist_ok=True)\n",
        "\n",
        "    # train 이미지 이동\n",
        "    for img in train_images:\n",
        "        shutil.copy(os.path.join(category_path, img), os.path.join(train_category_dir, img))\n",
        "\n",
        "    # validation 이미지 이동\n",
        "    for img in val_images:\n",
        "        shutil.copy(os.path.join(category_path, img), os.path.join(val_category_dir, img))\n",
        "\n",
        "    # test 이미지 이동\n",
        "    for img in test_images:\n",
        "        shutil.copy(os.path.join(category_path, img), os.path.join(test_category_dir, img))\n",
        "\n",
        "    print(f\"'{category}' 클래스에서 Train: {len(train_images)}개, Validation: {len(val_images)}개, Test: {len(test_images)}개 파일이 이동되었습니다.\")\n",
        "\n",
        "print(\"Train/Validation/Test 데이터 분리가 완료되었습니다!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qc3oT8-t1FV",
        "outputId": "7a694661-9671-4c39-9668-a045d14108aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'dreadlocks' 클래스에서 Train: 310개, Validation: 88개, Test: 45개 파일이 이동되었습니다.\n",
            "'Wavy' 클래스에서 Train: 230개, Validation: 66개, Test: 33개 파일이 이동되었습니다.\n",
            "'curly' 클래스에서 Train: 359개, Validation: 103개, Test: 52개 파일이 이동되었습니다.\n",
            "'kinky' 클래스에서 Train: 151개, Validation: 44개, Test: 22개 파일이 이동되었습니다.\n",
            "'Straight' 클래스에서 Train: 339개, Validation: 97개, Test: 49개 파일이 이동되었습니다.\n",
            "Train/Validation/Test 데이터 분리가 완료되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# 데이터 로드\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "# DataLoader 생성\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "UQ3yXQ9nt4Xy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning with Early Stopping"
      ],
      "metadata": {
        "id": "FT_I6PW7syyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "\n",
        "model.head = nn.Linear(model.head.in_features, 5)\n",
        "\n",
        "torch.nn.init.xavier_uniform_(model.head.weight)\n",
        "torch.nn.init.zeros_(model.head.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c69dfe-62e0-4314-f697-089a76ecd39e",
        "id": "Xt7Js8aOgvcm"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0., 0., 0., 0., 0.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습률 스케줄러 (옵션)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "0kJiQ9Ofgvcm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device 설정: GPU가 사용 가능하면 GPU, 아니면 CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = model.to(device)  # 모델을 지정된 device로 이동"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3771df-b557-4880-e794-e25bc5b2b4f5",
        "id": "FOUEda-0gvcn"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = []\n",
        "test_labels = []  # 실제 레이블 저장\n",
        "predicted_labels = []  # 예측된 레이블 저장\n",
        "\n",
        "# 하위 폴더를 순회하며 이미지와 레이블을 로드\n",
        "try:\n",
        "    label_mapping = {label: idx for idx, label in enumerate(sorted(os.listdir(test_dir)))}\n",
        "    reverse_mapping = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "    for category in os.listdir(test_dir):\n",
        "        category_path = os.path.join(test_dir, category)\n",
        "        if not os.path.isdir(category_path):\n",
        "            continue\n",
        "\n",
        "        for file_name in os.listdir(category_path):\n",
        "            file_path = os.path.join(category_path, file_name)\n",
        "            if file_name.lower().endswith(valid_extensions):  # 유효한 이미지 파일인지 확인\n",
        "                try:\n",
        "                    # 폴더 이름을 레이블로 사용\n",
        "                    label = label_mapping[category]\n",
        "                    test_labels.append(label)\n",
        "\n",
        "                    # 이미지 열기 및 전처리\n",
        "                    img = Image.open(file_path).convert(\"RGB\")\n",
        "                    img_tensor = transform(img).unsqueeze(0).to(device)  # 배치 차원 추가\n",
        "\n",
        "                    # 모델 예측\n",
        "                    with torch.no_grad():\n",
        "                        output = model(img_tensor)\n",
        "                        predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "                    # 예측된 레이블 저장\n",
        "                    predicted_labels.append(predicted_class)\n",
        "                except Exception as e:\n",
        "                    print(f\"이미지 처리 실패: {file_name}, 오류: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"테스트 데이터 로드 중 오류 발생: {e}\")"
      ],
      "metadata": {
        "id": "6WclKFV4gvcn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_tensor = img_tensor.to(device)  # 이미지를 동일한 device로 이동"
      ],
      "metadata": {
        "id": "B4xaVlRBgvcn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping 기준 설정\n",
        "patience = 3  # 성능 향상이 없을 때 기다리는 최대 에포크 수\n",
        "best_val_loss = float('inf')  # 검증 손실 최솟값 초기화\n",
        "patience_counter = 0  # patience 카운터 초기화\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 100  # 최대 에포크 수 설정\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()  # 에포크 시작 시간 기록\n",
        "\n",
        "    # 모델 학습 모드\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # 옵티마이저 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파 및 손실 계산\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 역전파 및 옵티마이저 업데이트\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 정확도 업데이트\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100. * correct / total\n",
        "\n",
        "    # 검증 루프\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = 100. * correct / total\n",
        "\n",
        "    # 에포크 종료 시간 기록\n",
        "    end_time = time.time()\n",
        "    epoch_duration = end_time - start_time\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
        "          f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%, Duration: {epoch_duration:.2f} seconds\")\n",
        "\n",
        "    # Early Stopping 검증\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        print(f\"Validation loss improved to {best_val_loss:.4f}. Model saved.\")\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")  # 모델 저장\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"No improvement in validation loss. Patience counter: {patience_counter}/{patience}\")\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# 학습 완료\n",
        "print(\"Training completed!\")\n",
        "\n",
        "# 테스트 루프\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))  # 가장 성능 좋은 모델 로드\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "test_accuracy = 100. * correct / total\n",
        "print(f\"테스트 데이터 정확도: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aluDzXLwfcql",
        "outputId": "1994b8e2-32a1-4d5b-f683-f11dab82e450"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Train Loss: 0.8823, Train Accuracy: 70.53%, Validation Loss: 0.4907, Validation Accuracy: 84.42%, Duration: 24.58 seconds\n",
            "Validation loss improved to 0.4907. Model saved.\n",
            "Epoch [2/100], Train Loss: 0.2095, Train Accuracy: 91.93%, Validation Loss: 0.4292, Validation Accuracy: 85.93%, Duration: 24.52 seconds\n",
            "Validation loss improved to 0.4292. Model saved.\n",
            "Epoch [3/100], Train Loss: 0.1229, Train Accuracy: 95.24%, Validation Loss: 0.4332, Validation Accuracy: 84.92%, Duration: 24.47 seconds\n",
            "No improvement in validation loss. Patience counter: 1/3\n",
            "Epoch [4/100], Train Loss: 0.1240, Train Accuracy: 95.39%, Validation Loss: 0.3324, Validation Accuracy: 90.70%, Duration: 24.53 seconds\n",
            "Validation loss improved to 0.3324. Model saved.\n",
            "Epoch [5/100], Train Loss: 0.0555, Train Accuracy: 97.98%, Validation Loss: 0.3582, Validation Accuracy: 90.45%, Duration: 24.67 seconds\n",
            "No improvement in validation loss. Patience counter: 1/3\n",
            "Epoch [6/100], Train Loss: 0.0817, Train Accuracy: 97.62%, Validation Loss: 0.3500, Validation Accuracy: 88.94%, Duration: 24.53 seconds\n",
            "No improvement in validation loss. Patience counter: 2/3\n",
            "Epoch [7/100], Train Loss: 0.0432, Train Accuracy: 98.70%, Validation Loss: 0.4973, Validation Accuracy: 86.93%, Duration: 24.49 seconds\n",
            "No improvement in validation loss. Patience counter: 3/3\n",
            "Early stopping triggered.\n",
            "Training completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-31407dd014ab>:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"best_model.pth\"))  # 가장 성능 좋은 모델 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 정확도: 91.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning with Freezing Blocks"
      ],
      "metadata": {
        "id": "7avJZ8swK0X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "\n",
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "\n",
        "model.head = nn.Linear(model.head.in_features, 5)\n",
        "\n",
        "torch.nn.init.xavier_uniform_(model.head.weight)\n",
        "torch.nn.init.zeros_(model.head.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGYoUHGmQJ8M",
        "outputId": "9c1c2162-05b2-47b1-967a-f9115a8fb18b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0., 0., 0., 0., 0.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습률 스케줄러 (옵션)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "FD1HQv6vK1lw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device 설정: GPU가 사용 가능하면 GPU, 아니면 CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = model.to(device)  # 모델을 지정된 device로 이동"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viLAsEKGQisb",
        "outputId": "2cbb5e59-e220-4189-c32e-eb89c28c5db8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = []\n",
        "test_labels = []  # 실제 레이블 저장\n",
        "predicted_labels = []  # 예측된 레이블 저장\n",
        "\n",
        "# 하위 폴더를 순회하며 이미지와 레이블을 로드\n",
        "try:\n",
        "    label_mapping = {label: idx for idx, label in enumerate(sorted(os.listdir(test_dir)))}\n",
        "    reverse_mapping = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "    for category in os.listdir(test_dir):\n",
        "        category_path = os.path.join(test_dir, category)\n",
        "        if not os.path.isdir(category_path):\n",
        "            continue\n",
        "\n",
        "        for file_name in os.listdir(category_path):\n",
        "            file_path = os.path.join(category_path, file_name)\n",
        "            if file_name.lower().endswith(valid_extensions):  # 유효한 이미지 파일인지 확인\n",
        "                try:\n",
        "                    # 폴더 이름을 레이블로 사용\n",
        "                    label = label_mapping[category]\n",
        "                    test_labels.append(label)\n",
        "\n",
        "                    # 이미지 열기 및 전처리\n",
        "                    img = Image.open(file_path).convert(\"RGB\")\n",
        "                    img_tensor = transform(img).unsqueeze(0).to(device)  # 배치 차원 추가\n",
        "\n",
        "                    # 모델 예측\n",
        "                    with torch.no_grad():\n",
        "                        output = model(img_tensor)\n",
        "                        predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "                    # 예측된 레이블 저장\n",
        "                    predicted_labels.append(predicted_class)\n",
        "                except Exception as e:\n",
        "                    print(f\"이미지 처리 실패: {file_name}, 오류: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"테스트 데이터 로드 중 오류 발생: {e}\")"
      ],
      "metadata": {
        "id": "6z_OJyh2j0N_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_tensor = img_tensor.to(device)  # 이미지를 동일한 device로 이동"
      ],
      "metadata": {
        "id": "vQTJPwwXQuH3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_gradients_and_freeze(model, freeze_threshold):\n",
        "    gradient_logs = []  # 각 블록의 Gradient 정보를 저장\n",
        "    all_frozen = True  # 모든 블록이 frozen 상태인지 확인\n",
        "\n",
        "    for idx, block in enumerate(model.blocks):\n",
        "        # 이미 frozen된 블록은 건너뜀\n",
        "        if not any(param.requires_grad for param in block.parameters()):\n",
        "            gradient_logs.append(0.0)  # Frozen 블록의 Gradient를 0으로 처리\n",
        "            continue\n",
        "\n",
        "        # Frozen되지 않은 블록이 존재하면 all_frozen은 False\n",
        "        all_frozen = False\n",
        "\n",
        "        total_grad = 0.0\n",
        "        num_params = 0\n",
        "        for param in block.parameters():\n",
        "            if param.grad is not None:\n",
        "                total_grad += param.grad.norm().item()  # 기울기의 L2 노름 계산\n",
        "                num_params += 1\n",
        "        avg_grad = total_grad / max(1, num_params)  # 평균 기울기\n",
        "        gradient_logs.append(avg_grad)\n",
        "\n",
        "        # Freezing 조건\n",
        "        if avg_grad < freeze_threshold:\n",
        "            for param in block.parameters():\n",
        "                param.requires_grad = False\n",
        "            print(f\"Block {idx} is frozen (Gradient: {avg_grad:.6f}).\")\n",
        "\n",
        "    return gradient_logs, all_frozen"
      ],
      "metadata": {
        "id": "VFC1BrNLp45g"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프\n",
        "freeze_threshold = 1e-3  # 블록을 freezing할 기울기 크기 임계값\n",
        "epoch = 0  # 에포크 수 초기화\n",
        "\n",
        "while True:\n",
        "    epoch += 1  # 에포크 증가\n",
        "    start_time = time.time()  # 에포크 시작 시간 기록\n",
        "\n",
        "    model.train()  # 모델 학습 모드\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    max_gradients = []  # 모든 블록의 Gradient Magnitude 기록용 리스트\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # 옵티마이저 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파 및 손실 계산\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 역전파\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient 크기 로깅 및 Freezing\n",
        "        gradient_logs, all_frozen = log_gradients_and_freeze(model, freeze_threshold)\n",
        "        max_gradients.extend(gradient_logs)  # Gradient Magnitudes 누적\n",
        "\n",
        "        # 옵티마이저 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 정확도 계산\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # 에포크 종료 시간 기록\n",
        "    end_time = time.time()\n",
        "    epoch_duration = end_time - start_time  # 에포크 소요 시간 계산\n",
        "\n",
        "    print(f\"Epoch [{epoch}], Loss: {running_loss/len(train_loader):.4f}, \"\n",
        "          f\"Accuracy: {100.*correct/total:.2f}%, Duration: {epoch_duration:.2f} seconds\")\n",
        "\n",
        "    # 학습률 스케줄러 업데이트 (옵션)\n",
        "    scheduler.step()\n",
        "\n",
        "    # 모든 블록이 frozen 상태라면 학습 종료\n",
        "    if all_frozen:\n",
        "        print(f\"All blocks are frozen. Training stopped at Epoch {epoch}.\")\n",
        "        break\n",
        "\n",
        "# 학습 완료\n",
        "print(\"Fine-Tuning 완료!\")"
      ],
      "metadata": {
        "id": "Cj-uqbAlI-SR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2332d8-244b-4176-e4fb-c9d30da4198a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Loss: 1.0947, Accuracy: 65.78%, Duration: 21.25 seconds\n",
            "Epoch [2], Loss: 0.2321, Accuracy: 91.21%, Duration: 21.03 seconds\n",
            "Epoch [3], Loss: 0.1451, Accuracy: 95.53%, Duration: 21.22 seconds\n",
            "Epoch [4], Loss: 0.2373, Accuracy: 91.14%, Duration: 21.09 seconds\n",
            "Epoch [5], Loss: 0.1124, Accuracy: 96.40%, Duration: 21.11 seconds\n",
            "Epoch [6], Loss: 0.0567, Accuracy: 98.05%, Duration: 21.11 seconds\n",
            "Epoch [7], Loss: 0.0401, Accuracy: 98.70%, Duration: 21.10 seconds\n",
            "Block 1 is frozen (Gradient: 0.000823).\n",
            "Block 2 is frozen (Gradient: 0.000852).\n",
            "Block 3 is frozen (Gradient: 0.000793).\n",
            "Block 4 is frozen (Gradient: 0.000872).\n",
            "Block 5 is frozen (Gradient: 0.000898).\n",
            "Block 6 is frozen (Gradient: 0.000898).\n",
            "Block 7 is frozen (Gradient: 0.000918).\n",
            "Epoch [8], Loss: 0.0076, Accuracy: 99.86%, Duration: 19.63 seconds\n",
            "Block 11 is frozen (Gradient: 0.000844).\n",
            "Epoch [9], Loss: 0.0040, Accuracy: 99.93%, Duration: 19.05 seconds\n",
            "Epoch [10], Loss: 0.0033, Accuracy: 99.93%, Duration: 18.91 seconds\n",
            "Block 0 is frozen (Gradient: 0.000834).\n",
            "Block 8 is frozen (Gradient: 0.000852).\n",
            "Block 9 is frozen (Gradient: 0.000854).\n",
            "Block 10 is frozen (Gradient: 0.000838).\n",
            "Epoch [11], Loss: 0.0029, Accuracy: 99.93%, Duration: 18.17 seconds\n",
            "Epoch [12], Loss: 0.0028, Accuracy: 99.93%, Duration: 17.91 seconds\n",
            "All blocks are frozen. Training stopped at Epoch 12.\n",
            "Fine-Tuning 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 모드\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "print(f\"테스트 데이터 정확도: {100.*correct/total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CteH8hnASKO0",
        "outputId": "b75aa37b-3f03-4a01-8a20-090290186108"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 정확도: 91.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hook 함수 정의\n",
        "feature_maps = []\n",
        "\n",
        "def hook_fn(module, input, output):\n",
        "    feature_maps.append(output)\n",
        "\n",
        "# Transformer 블록에 Hook 등록\n",
        "num_blocks = len(model.blocks)  # Transformer 블록의 개수를 자동으로 계산\n",
        "for i in range(num_blocks):\n",
        "    model.blocks[i].register_forward_hook(hook_fn)\n",
        "\n",
        "# 모델 추론\n",
        "with torch.no_grad():\n",
        "    _ = model(img_tensor)\n",
        "\n",
        "# Feature Maps 시각화\n",
        "num_blocks = len(feature_maps)  # Transformer 블록의 수\n",
        "fig, axes = plt.subplots(1, num_blocks, figsize=(20, 5))  # 가로로 블록 수만큼의 서브플롯 생성\n",
        "\n",
        "for i, (ax, block_feature_map) in enumerate(zip(axes, feature_maps)):\n",
        "    # 클래스 토큰 제거\n",
        "    block_feature_map_patches = block_feature_map[0, 1:, :]  # [1, 197, 768] → [196, 768]\n",
        "\n",
        "    # 14x14 형태로 변환\n",
        "    patch_size = int(block_feature_map_patches.size(0) ** 0.5)  # 14 (CIFAR-10에서는 196 → 14x14)\n",
        "    feature_map_2d = block_feature_map_patches.view(patch_size, patch_size, -1)\n",
        "\n",
        "    # 평균값으로 축소하여 시각화\n",
        "    feature_map_avg = feature_map_2d.mean(dim=-1).cpu().detach().numpy()\n",
        "\n",
        "    # 서브플롯에 Feature Map 시각화\n",
        "    ax.imshow(feature_map_avg, cmap='viridis')\n",
        "    ax.set_title(f\"Block {i}\")\n",
        "    ax.axis(\"off\")  # 축 제거\n",
        "\n",
        "# 레이아웃 조정 및 표시\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M-3LdVxHpkfu",
        "outputId": "75643170-caec-4761-d678-651009665972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}