{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNOXUtqGMCsaZ99OLEcoole",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sehee020512/20242R0136COSE47402/blob/master/final%20project%2012.3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "QoU1QQqgsdR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow\n",
        "!pip install transformers\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "qXh8T6yA527A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8695aff-42bb-49fa-c6fb-458ebc29c49f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import shutil\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "metadata": {
        "id": "mnufGblp5uub"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2dVkFJlielk",
        "outputId": "0addf6e3-1550-4a6f-a6cb-19b8b6484761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/kavyasreeb/hair-type-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175M/175M [00:09<00:00, 20.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/kavyasreeb/hair-type-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"kavyasreeb/hair-type-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 데이터 경로\n",
        "source_path = \"/root/.cache/kagglehub/datasets/kavyasreeb/hair-type-dataset/versions/1\"\n",
        "\n",
        "# 복사할 대상 경로\n",
        "destination_path = \"/content/hair-type-dataset\"\n",
        "\n",
        "# 데이터 복사\n",
        "try:\n",
        "    shutil.copytree(source_path, destination_path)\n",
        "    print(f\"데이터가 {destination_path}에 복사되었습니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"복사 실패: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFi9T1TTzlJK",
        "outputId": "1fdac079-fe32-471e-b7d7-45d46c515abd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터가 /content/hair-type-dataset에 복사되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 경로 설정\n",
        "dataset_dir = \"/content/hair-type-dataset/data\"  # 클래스별 이미지가 있는 디렉토리\n",
        "train_dir = \"/content/train\"  # train 데이터 저장 경로\n",
        "test_dir = \"/content/test\"  # test 데이터 저장 경로\n",
        "\n",
        "# train/test 디렉토리 생성\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# 이미지 확장자 필터\n",
        "valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
        "\n",
        "# 클래스별 train/test 데이터 분리\n",
        "split_ratio = 0.8  # Train 80%, Test 20%\n",
        "for category in os.listdir(dataset_dir):\n",
        "    category_path = os.path.join(dataset_dir, category)\n",
        "    if not os.path.isdir(category_path):\n",
        "        continue  # 디렉토리가 아니면 건너뜀\n",
        "\n",
        "    # 클래스별 이미지 파일 가져오기\n",
        "    images = [img for img in os.listdir(category_path) if img.lower().endswith(valid_extensions)]\n",
        "\n",
        "    # 이미지가 없으면 건너뜀\n",
        "    if len(images) == 0:\n",
        "        print(f\"'{category}' 폴더에 이미지가 없습니다. 건너뜁니다.\")\n",
        "        continue\n",
        "\n",
        "    # train/test로 분리\n",
        "    train_images, test_images = train_test_split(images, test_size=1 - split_ratio, random_state=42)\n",
        "\n",
        "    # 클래스별 train/test 디렉토리 생성\n",
        "    train_category_dir = os.path.join(train_dir, category)\n",
        "    test_category_dir = os.path.join(test_dir, category)\n",
        "    os.makedirs(train_category_dir, exist_ok=True)\n",
        "    os.makedirs(test_category_dir, exist_ok=True)\n",
        "\n",
        "    # train 이미지 이동\n",
        "    for img in train_images:\n",
        "        shutil.copy(os.path.join(category_path, img), os.path.join(train_category_dir, img))\n",
        "\n",
        "    # test 이미지 이동\n",
        "    for img in test_images:\n",
        "        shutil.copy(os.path.join(category_path, img), os.path.join(test_category_dir, img))\n",
        "\n",
        "    print(f\"'{category}' 클래스에서 Train: {len(train_images)}개, Test: {len(test_images)}개 파일이 이동되었습니다.\")\n",
        "\n",
        "print(\"Train/Test 데이터 분리가 완료되었습니다!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qc3oT8-t1FV",
        "outputId": "99608c5a-0e60-422e-a0b9-da0177497641"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Straight' 클래스에서 Train: 388개, Test: 97개 파일이 이동되었습니다.\n",
            "'curly' 클래스에서 Train: 411개, Test: 103개 파일이 이동되었습니다.\n",
            "'kinky' 클래스에서 Train: 173개, Test: 44개 파일이 이동되었습니다.\n",
            "'Wavy' 클래스에서 Train: 263개, Test: 66개 파일이 이동되었습니다.\n",
            "'dreadlocks' 클래스에서 Train: 354개, Test: 89개 파일이 이동되었습니다.\n",
            "Train/Test 데이터 분리가 완료되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # DeiT 입력 크기\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# 데이터 로드\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "# DataLoader 생성\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "UQ3yXQ9nt4Xy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning w/o Freezing"
      ],
      "metadata": {
        "id": "FT_I6PW7syyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
        "\n",
        "model.head = nn.Linear(model.head.in_features, 5)\n",
        "\n",
        "torch.nn.init.xavier_uniform_(model.head.weight)\n",
        "torch.nn.init.zeros_(model.head.bias)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "GmWysrgapoi4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 동결된 파라미터와 학습 가능한 파라미터 확인\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: requires_grad={param.requires_grad}\")"
      ],
      "metadata": {
        "id": "MrugA_nnPHYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device 설정: GPU가 사용 가능하면 GPU, 아니면 CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = model.to(device)  # 모델을 지정된 device로 이동"
      ],
      "metadata": {
        "id": "rFJ80Lsc2FXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = []\n",
        "test_labels = []  # 실제 레이블 저장\n",
        "predicted_labels = []  # 예측된 레이블 저장\n",
        "\n",
        "# 하위 폴더를 순회하며 이미지와 레이블을 로드\n",
        "try:\n",
        "    label_mapping = {label: idx for idx, label in enumerate(sorted(os.listdir(test_dir)))}\n",
        "    reverse_mapping = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "    for category in os.listdir(test_dir):\n",
        "        category_path = os.path.join(test_dir, category)\n",
        "        if not os.path.isdir(category_path):\n",
        "            continue\n",
        "\n",
        "        for file_name in os.listdir(category_path):\n",
        "            file_path = os.path.join(category_path, file_name)\n",
        "            if file_name.lower().endswith(valid_extensions):  # 유효한 이미지 파일인지 확인\n",
        "                try:\n",
        "                    # 폴더 이름을 레이블로 사용\n",
        "                    label = label_mapping[category]\n",
        "                    test_labels.append(label)\n",
        "\n",
        "                    # 이미지 열기 및 전처리\n",
        "                    img = Image.open(file_path).convert(\"RGB\")\n",
        "                    img_tensor = transform(img).unsqueeze(0).to(device)  # 배치 차원 추가\n",
        "\n",
        "                    # 모델 예측\n",
        "                    with torch.no_grad():\n",
        "                        output = model(img_tensor)\n",
        "                        predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "                    # 예측된 레이블 저장\n",
        "                    predicted_labels.append(predicted_class)\n",
        "                except Exception as e:\n",
        "                    print(f\"이미지 처리 실패: {file_name}, 오류: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"테스트 데이터 로드 중 오류 발생: {e}\")\n",
        "\n",
        "# 4. 정확도 계산 및 출력\n",
        "if test_labels and predicted_labels:\n",
        "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "    print(f\"테스트 데이터 개수: {len(test_labels)}\")\n",
        "    print(f\"정확도: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 예측 결과 예시 출력\n",
        "    for i in range(len(test_labels)):\n",
        "        true_label = reverse_mapping[test_labels[i]]\n",
        "        predicted_label = reverse_mapping[predicted_labels[i]]\n",
        "else:\n",
        "    print(\"테스트 데이터가 비어 있거나 예측 결과가 없습니다.\")"
      ],
      "metadata": {
        "id": "Y_-l6KQ3w8yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GgmcvKXF3xoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_tensor = img_tensor.to(device)  # 이미지를 동일한 device로 이동"
      ],
      "metadata": {
        "id": "Y0A57mnlLUX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습률 스케줄러 (옵션)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "19ozGpWi3fAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time  # 시간을 측정하기 위한 모듈\n",
        "\n",
        "num_epochs = 10  # 에포크 수\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()  # 에포크 시작 시간 기록\n",
        "\n",
        "    # 모델 학습 모드\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # 옵티마이저 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파 및 손실 계산\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 역전파 및 옵티마이저 업데이트\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실과 정확도 업데이트\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # 에포크 종료 시간 기록\n",
        "    end_time = time.time()\n",
        "    epoch_duration = end_time - start_time  # 에포크 소요 시간 계산\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, \"\n",
        "          f\"Accuracy: {100.*correct/total:.2f}%, Duration: {epoch_duration:.2f} seconds\")\n",
        "\n",
        "    # 학습률 스케줄러 업데이트 (옵션)\n",
        "    scheduler.step()\n",
        "\n",
        "# 학습 완료\n",
        "print(\"Fine-Tuning 완료!\")"
      ],
      "metadata": {
        "id": "ZjB9_EWS3wy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hook 함수 정의\n",
        "feature_maps = []\n",
        "\n",
        "def hook_fn(module, input, output):\n",
        "    feature_maps.append(output)\n",
        "\n",
        "# Transformer 블록에 Hook 등록\n",
        "for i in range(0, 12):\n",
        "  model.blocks[i].register_forward_hook(hook_fn)\n",
        "\n",
        "# 모델 추론\n",
        "with torch.no_grad():\n",
        "    _ = model(img_tensor)\n",
        "\n",
        "# 블록별 Feature Map 출력\n",
        "for i, feature_map in enumerate(feature_maps):"
      ],
      "metadata": {
        "id": "eDUfx3f5384s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Maps 시각화\n",
        "num_blocks = len(feature_maps)  # Transformer 블록의 수\n",
        "fig, axes = plt.subplots(1, num_blocks, figsize=(20, 5))  # 가로로 블록 수만큼의 서브플롯 생성\n",
        "\n",
        "for i, (ax, block_feature_map) in enumerate(zip(axes, feature_maps)):\n",
        "    # 클래스 토큰 제거\n",
        "    block_feature_map_patches = block_feature_map[0, 1:, :]  # 배치 차원 0 제거, [1, 197, 768] → [196, 768]\n",
        "\n",
        "    # 14x14 형태로 변환\n",
        "    patch_size = int(block_feature_map_patches.size(0) ** 0.5)  # 14\n",
        "    feature_map_2d = block_feature_map_patches.view(patch_size, patch_size, -1)\n",
        "\n",
        "    # 평균값으로 축소하여 시각화\n",
        "    feature_map_avg = feature_map_2d.mean(axis=-1).cpu().detach().numpy()\n",
        "\n",
        "    # 서브플롯에 Feature Map 시각화\n",
        "    ax.imshow(feature_map_avg, cmap='viridis')\n",
        "    ax.set_title(f\"Block {i}\")\n",
        "    ax.axis(\"off\")  # 축 제거\n",
        "\n",
        "# 레이아웃 조정 및 표시\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V5zmrZwz36Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 모드\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "print(f\"테스트 데이터 정확도: {100.*correct/total:.2f}%\")"
      ],
      "metadata": {
        "id": "qUF_gksW4Noi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning w/ Freezing"
      ],
      "metadata": {
        "id": "7avJZ8swK0X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
        "\n",
        "model.head = nn.Linear(model.head.in_features, 5)\n",
        "\n",
        "torch.nn.init.xavier_uniform_(model.head.weight)\n",
        "torch.nn.init.zeros_(model.head.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGYoUHGmQJ8M",
        "outputId": "42054ad1-fb47-46a3-8266-22c0977f5c68"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0., 0., 0., 0., 0.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습률 스케줄러 (옵션)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "# 동결된 파라미터와 학습 가능한 파라미터 확인\n",
        "for name, param in model.named_parameters():\n",
        "    if not param.requires_grad:\n",
        "        print(f\"{name}: requires_grad={param.requires_grad}\")"
      ],
      "metadata": {
        "id": "FD1HQv6vK1lw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device 설정: GPU가 사용 가능하면 GPU, 아니면 CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = model.to(device)  # 모델을 지정된 device로 이동"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viLAsEKGQisb",
        "outputId": "ca5ffe29-fafd-4f55-ecf5-f56d0864608f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = []\n",
        "test_labels = []  # 실제 레이블 저장\n",
        "predicted_labels = []  # 예측된 레이블 저장\n",
        "\n",
        "# 하위 폴더를 순회하며 이미지와 레이블을 로드\n",
        "try:\n",
        "    label_mapping = {label: idx for idx, label in enumerate(sorted(os.listdir(test_dir)))}\n",
        "    reverse_mapping = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "    for category in os.listdir(test_dir):\n",
        "        category_path = os.path.join(test_dir, category)\n",
        "        if not os.path.isdir(category_path):\n",
        "            continue\n",
        "\n",
        "        for file_name in os.listdir(category_path):\n",
        "            file_path = os.path.join(category_path, file_name)\n",
        "            if file_name.lower().endswith(valid_extensions):  # 유효한 이미지 파일인지 확인\n",
        "                try:\n",
        "                    # 폴더 이름을 레이블로 사용\n",
        "                    label = label_mapping[category]\n",
        "                    test_labels.append(label)\n",
        "\n",
        "                    # 이미지 열기 및 전처리\n",
        "                    img = Image.open(file_path).convert(\"RGB\")\n",
        "                    img_tensor = transform(img).unsqueeze(0).to(device)  # 배치 차원 추가\n",
        "\n",
        "                    # 모델 예측\n",
        "                    with torch.no_grad():\n",
        "                        output = model(img_tensor)\n",
        "                        predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "                    # 예측된 레이블 저장\n",
        "                    predicted_labels.append(predicted_class)\n",
        "                except Exception as e:\n",
        "                    print(f\"이미지 처리 실패: {file_name}, 오류: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"테스트 데이터 로드 중 오류 발생: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGd6gRnIQrbV",
        "outputId": "92ecadb9-ff84-4256-8a5c-05e91e9db869"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 개수: 399\n",
            "정확도: 25.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 정확도 계산 및 출력\n",
        "if test_labels and predicted_labels:\n",
        "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "    print(f\"테스트 데이터 개수: {len(test_labels)}\")\n",
        "    print(f\"정확도: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 예측 결과 예시 출력\n",
        "    for i in range(len(test_labels)):\n",
        "        true_label = reverse_mapping[test_labels[i]]\n",
        "        predicted_label = reverse_mapping[predicted_labels[i]]\n",
        "else:\n",
        "    print(\"테스트 데이터가 비어 있거나 예측 결과가 없습니다.\")"
      ],
      "metadata": {
        "id": "ynoHnHqzJF1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_tensor = img_tensor.to(device)  # 이미지를 동일한 device로 이동"
      ],
      "metadata": {
        "id": "vQTJPwwXQuH3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_gradients_and_freeze(model, freeze_threshold):\n",
        "    gradient_logs = []  # 각 블록의 Gradient 정보를 저장\n",
        "    all_frozen = True  # 모든 블록이 frozen 상태인지 확인\n",
        "\n",
        "    for idx, block in enumerate(model.blocks):\n",
        "        # 이미 frozen된 블록은 건너뜀\n",
        "        if not any(param.requires_grad for param in block.parameters()):\n",
        "            gradient_logs.append(0.0)  # Frozen 블록의 Gradient를 0으로 처리\n",
        "            continue\n",
        "\n",
        "        # Frozen되지 않은 블록이 존재하면 all_frozen은 False\n",
        "        all_frozen = False\n",
        "\n",
        "        total_grad = 0.0\n",
        "        num_params = 0\n",
        "        for param in block.parameters():\n",
        "            if param.grad is not None:\n",
        "                total_grad += param.grad.norm().item()  # 기울기의 L2 노름 계산\n",
        "                num_params += 1\n",
        "        avg_grad = total_grad / max(1, num_params)  # 평균 기울기\n",
        "        gradient_logs.append(avg_grad)\n",
        "\n",
        "        # Freezing 조건\n",
        "        if avg_grad < freeze_threshold:\n",
        "            for param in block.parameters():\n",
        "                param.requires_grad = False\n",
        "            print(f\"Block {idx} is frozen (Gradient: {avg_grad:.6f}).\")\n",
        "\n",
        "    return gradient_logs, all_frozen"
      ],
      "metadata": {
        "id": "VFC1BrNLp45g"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프\n",
        "freeze_threshold = 1e-3  # 블록을 freezing할 기울기 크기 임계값\n",
        "epoch = 0  # 에포크 수 초기화\n",
        "\n",
        "while True:\n",
        "    epoch += 1  # 에포크 증가\n",
        "    start_time = time.time()  # 에포크 시작 시간 기록\n",
        "\n",
        "    model.train()  # 모델 학습 모드\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    max_gradients = []  # 모든 블록의 Gradient Magnitude 기록용 리스트\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # 옵티마이저 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파 및 손실 계산\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 역전파\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient 크기 로깅 및 Freezing\n",
        "        gradient_logs, all_frozen = log_gradients_and_freeze(model, freeze_threshold)\n",
        "        max_gradients.extend(gradient_logs)  # Gradient Magnitudes 누적\n",
        "\n",
        "        # 옵티마이저 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 정확도 계산\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # Gradient Magnitude 히스토그램 출력\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(max_gradients, bins=50, alpha=0.75, label='Gradient Magnitudes')\n",
        "    plt.title(f\"Epoch {epoch}: Gradient Magnitude Distribution\")\n",
        "    plt.xlabel(\"Gradient Magnitude\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # 에포크 종료 시간 기록\n",
        "    end_time = time.time()\n",
        "    epoch_duration = end_time - start_time  # 에포크 소요 시간 계산\n",
        "\n",
        "    print(f\"Epoch [{epoch}], Loss: {running_loss/len(train_loader):.4f}, \"\n",
        "          f\"Accuracy: {100.*correct/total:.2f}%, Duration: {epoch_duration:.2f} seconds\")\n",
        "\n",
        "    # 학습률 스케줄러 업데이트 (옵션)\n",
        "    scheduler.step()\n",
        "\n",
        "    # 모든 블록이 frozen 상태라면 학습 종료\n",
        "    if all_frozen:\n",
        "        print(f\"All blocks are frozen. Training stopped at Epoch {epoch}.\")\n",
        "        break\n",
        "\n",
        "# 학습 완료\n",
        "print(\"Fine-Tuning 완료!\")"
      ],
      "metadata": {
        "id": "Cj-uqbAlI-SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 모드\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "print(f\"테스트 데이터 정확도: {100.*correct/total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CteH8hnASKO0",
        "outputId": "62d957bf-a4a9-4a30-b600-f6c37657b672"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 정확도: 91.46%\n"
          ]
        }
      ]
    }
  ]
}