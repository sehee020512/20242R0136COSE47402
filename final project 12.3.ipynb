{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMpjLNioCHJOT7zec7nQiAA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sehee020512/20242R0136COSE47402/blob/master/final%20project%2012.3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "QoU1QQqgsdR-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2dVkFJlielk",
        "outputId": "f350f9b1-32ac-471a-a26a-8eb9430db6d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/kavyasreeb/hair-type-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"kavyasreeb/hair-type-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# 원본 데이터 경로\n",
        "source_path = \"/root/.cache/kagglehub/datasets/kavyasreeb/hair-type-dataset/versions/1\"\n",
        "\n",
        "# 복사할 대상 경로\n",
        "destination_path = \"/content/hair-type-dataset\"\n",
        "\n",
        "# 데이터 복사\n",
        "try:\n",
        "    shutil.copytree(source_path, destination_path)\n",
        "    print(f\"데이터가 {destination_path}에 복사되었습니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"복사 실패: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFi9T1TTzlJK",
        "outputId": "068fb3fa-f4bc-4559-b612-69e41b3fac1f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "복사 실패: [Errno 17] File exists: '/content/hair-type-dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 경로 설정\n",
        "dataset_dir = \"/content/hair-type-dataset/data\"  # 클래스별 이미지가 있는 디렉토리\n",
        "train_dir = \"/content/train\"  # train 데이터 저장 경로\n",
        "test_dir = \"/content/test\"  # test 데이터 저장 경로\n",
        "\n",
        "# train/test 디렉토리 생성\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# 이미지 확장자 필터\n",
        "valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
        "\n",
        "# 클래스별 train/test 데이터 분리\n",
        "split_ratio = 0.8  # Train 80%, Test 20%\n",
        "for category in os.listdir(dataset_dir):\n",
        "    category_path = os.path.join(dataset_dir, category)\n",
        "    if not os.path.isdir(category_path):\n",
        "        continue  # 디렉토리가 아니면 건너뜀\n",
        "\n",
        "    # 클래스별 이미지 파일 가져오기\n",
        "    images = [img for img in os.listdir(category_path) if img.lower().endswith(valid_extensions)]\n",
        "\n",
        "    # 이미지가 없으면 건너뜀\n",
        "    if len(images) == 0:\n",
        "        print(f\"'{category}' 폴더에 이미지가 없습니다. 건너뜁니다.\")\n",
        "        continue\n",
        "\n",
        "    # train/test로 분리\n",
        "    train_images, test_images = train_test_split(images, test_size=1 - split_ratio, random_state=42)\n",
        "\n",
        "    # 클래스별 train/test 디렉토리 생성\n",
        "    train_category_dir = os.path.join(train_dir, category)\n",
        "    test_category_dir = os.path.join(test_dir, category)\n",
        "    os.makedirs(train_category_dir, exist_ok=True)\n",
        "    os.makedirs(test_category_dir, exist_ok=True)\n",
        "\n",
        "    # train 이미지 이동\n",
        "    for img in train_images:\n",
        "        shutil.copy(os.path.join(category_path, img), os.path.join(train_category_dir, img))\n",
        "\n",
        "    # test 이미지 이동\n",
        "    for img in test_images:\n",
        "        shutil.copy(os.path.join(category_path, img), os.path.join(test_category_dir, img))\n",
        "\n",
        "    print(f\"'{category}' 클래스에서 Train: {len(train_images)}개, Test: {len(test_images)}개 파일이 이동되었습니다.\")\n",
        "\n",
        "print(\"Train/Test 데이터 분리가 완료되었습니다!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qc3oT8-t1FV",
        "outputId": "e793b085-c9cb-49ac-ef69-b0db14bc758e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'dreadlocks' 클래스에서 Train: 354개, Test: 89개 파일이 이동되었습니다.\n",
            "'Wavy' 클래스에서 Train: 263개, Test: 66개 파일이 이동되었습니다.\n",
            "'Straight' 클래스에서 Train: 388개, Test: 97개 파일이 이동되었습니다.\n",
            "'kinky' 클래스에서 Train: 173개, Test: 44개 파일이 이동되었습니다.\n",
            "'curly' 클래스에서 Train: 411개, Test: 103개 파일이 이동되었습니다.\n",
            "Train/Test 데이터 분리가 완료되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 데이터 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # DeiT 입력 크기\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# 데이터 로드\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "# DataLoader 생성\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "UQ3yXQ9nt4Xy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QFDSnCex8ag",
        "outputId": "b7b54fe5-77ba-4be1-a7a6-5380a8f01387"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "TltF6JsKx-ps"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "FT_I6PW7syyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "VaPz1BITif2P",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a0b446-0f3f-4c90-8a31-994c17216dcb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "import torchvision\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "NBXqPSMVo6Bp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)"
      ],
      "metadata": {
        "id": "ve-9xpLdilnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d21574-a1ae-4134-e04e-54b63ff94074"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.head = nn.Linear(model.head.in_features, 5)\n",
        "\n",
        "torch.nn.init.xavier_uniform_(model.head.weight)\n",
        "torch.nn.init.zeros_(model.head.bias)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmWysrgapoi4",
        "outputId": "073919c9-bc39-447c-8738-26f0767b0494",
        "collapsed": true
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VisionTransformer(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "    (norm): Identity()\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (patch_drop): Identity()\n",
            "  (norm_pre): Identity()\n",
            "  (blocks): Sequential(\n",
            "    (0): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (1): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (2): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (3): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (4): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (5): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (6): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (7): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (8): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (9): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (10): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (11): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (fc_norm): Identity()\n",
            "  (head_drop): Dropout(p=0.0, inplace=False)\n",
            "  (head): Linear(in_features=768, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)  # GPU 또는 CPU로 모델 이동\n",
        "img_tensor = img_tensor.to(device)  # GPU 또는 CPU로 텐서 이동"
      ],
      "metadata": {
        "id": "ey3uUqAs1IV9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4mVy1GX2lZI",
        "outputId": "bed6da86-6bad-4ae0-967e-3ed8f372fd1a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "from sklearn.metrics import accuracy_score  # 정확도 계산 함수"
      ],
      "metadata": {
        "id": "E2qNQ4QN2o-T"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = []\n",
        "test_labels = []  # 실제 레이블 저장\n",
        "predicted_labels = []  # 예측된 레이블 저장\n",
        "\n",
        "# 하위 폴더를 순회하며 이미지와 레이블을 로드\n",
        "try:\n",
        "    label_mapping = {label: idx for idx, label in enumerate(sorted(os.listdir(test_dir)))}\n",
        "    reverse_mapping = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "    for category in os.listdir(test_dir):\n",
        "        category_path = os.path.join(test_dir, category)\n",
        "        if not os.path.isdir(category_path):\n",
        "            continue\n",
        "\n",
        "        for file_name in os.listdir(category_path):\n",
        "            file_path = os.path.join(category_path, file_name)\n",
        "            if file_name.lower().endswith(valid_extensions):  # 유효한 이미지 파일인지 확인\n",
        "                try:\n",
        "                    # 폴더 이름을 레이블로 사용\n",
        "                    label = label_mapping[category]\n",
        "                    test_labels.append(label)\n",
        "\n",
        "                    # 이미지 열기 및 전처리\n",
        "                    img = Image.open(file_path).convert(\"RGB\")\n",
        "                    img_tensor = transform(img).unsqueeze(0).to(device)  # 배치 차원 추가\n",
        "\n",
        "                    # 모델 예측\n",
        "                    with torch.no_grad():\n",
        "                        output = model(img_tensor)\n",
        "                        predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "                    # 예측된 레이블 저장\n",
        "                    predicted_labels.append(predicted_class)\n",
        "                except Exception as e:\n",
        "                    print(f\"이미지 처리 실패: {file_name}, 오류: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"테스트 데이터 로드 중 오류 발생: {e}\")\n",
        "\n",
        "# 4. 정확도 계산 및 출력\n",
        "if test_labels and predicted_labels:\n",
        "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "    print(f\"테스트 데이터 개수: {len(test_labels)}\")\n",
        "    print(f\"정확도: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 예측 결과 예시 출력\n",
        "    for i in range(len(test_labels)):\n",
        "        true_label = reverse_mapping[test_labels[i]]\n",
        "        predicted_label = reverse_mapping[predicted_labels[i]]\n",
        "        print(f\"실제: {true_label} | 예측: {predicted_label}\")\n",
        "else:\n",
        "    print(\"테스트 데이터가 비어 있거나 예측 결과가 없습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_-l6KQ3w8yv",
        "outputId": "b3b9a150-e2a4-412a-e92f-15c0b1cc152b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 개수: 399\n",
            "정확도: 23.31%\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: dreadlocks\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: dreadlocks\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: kinky\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: kinky\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: kinky\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: kinky\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Wavy\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: kinky\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: kinky\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: kinky\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning"
      ],
      "metadata": {
        "id": "GgmcvKXF3xoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "6GJ6GbUP3rzl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습률 스케줄러 (옵션)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "19ozGpWi3fAV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10  # 에포크 수\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # 모델 학습 모드\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # 옵티마이저 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파 및 손실 계산\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 역전파 및 옵티마이저 업데이트\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실과 정확도 업데이트\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100.*correct/total:.2f}%\")\n",
        "\n",
        "    # 학습률 스케줄러 업데이트 (옵션)\n",
        "    scheduler.step()\n",
        "\n",
        "# 학습 완료\n",
        "print(\"Fine-Tuning 완료!\")"
      ],
      "metadata": {
        "id": "ZjB9_EWS3wy3",
        "outputId": "0a9b34c2-5761-448f-c683-48569df4847a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5871, Accuracy: 77.14%\n",
            "Epoch [2/10], Loss: 0.1078, Accuracy: 96.03%\n",
            "Epoch [3/10], Loss: 0.0595, Accuracy: 98.05%\n",
            "Epoch [4/10], Loss: 0.0226, Accuracy: 99.50%\n",
            "Epoch [5/10], Loss: 0.0431, Accuracy: 98.55%\n",
            "Epoch [6/10], Loss: 0.0184, Accuracy: 99.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 모드\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "print(f\"테스트 데이터 정확도: {100.*correct/total:.2f}%\")"
      ],
      "metadata": {
        "id": "qUF_gksW4Noi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}