{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNN1KeBZ/qyvTlaKjl701iR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sehee020512/20242R0136COSE47402/blob/master/final%20project%2012.3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "QoU1QQqgsdR-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2dVkFJlielk",
        "outputId": "ebb0383f-4ba3-4724-9518-17142ae4ebb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/kavyasreeb/hair-type-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"kavyasreeb/hair-type-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# 원본 데이터 경로\n",
        "source_path = \"/root/.cache/kagglehub/datasets/kavyasreeb/hair-type-dataset/versions/1\"\n",
        "\n",
        "# 복사할 대상 경로\n",
        "destination_path = \"/content/hair-type-dataset\"\n",
        "\n",
        "# 데이터 복사\n",
        "try:\n",
        "    shutil.copytree(source_path, destination_path)\n",
        "    print(f\"데이터가 {destination_path}에 복사되었습니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"복사 실패: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFi9T1TTzlJK",
        "outputId": "c7f772c0-74f3-4aef-8dc4-17a90bf9a644"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "복사 실패: [Errno 17] File exists: '/content/hair-type-dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 경로 설정\n",
        "dataset_dir = \"/content/hair-type-dataset/data\"  # 클래스별 이미지가 있는 디렉토리\n",
        "train_dir = \"/content/train\"  # train 데이터 저장 경로\n",
        "test_dir = \"/content/test\"  # test 데이터 저장 경로\n",
        "\n",
        "# train/test 디렉토리 생성\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# 이미지 확장자 필터\n",
        "valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
        "\n",
        "# 클래스별 train/test 데이터 분리\n",
        "split_ratio = 0.8  # Train 80%, Test 20%\n",
        "for category in os.listdir(dataset_dir):\n",
        "    category_path = os.path.join(dataset_dir, category)\n",
        "    if not os.path.isdir(category_path):\n",
        "        continue  # 디렉토리가 아니면 건너뜀\n",
        "\n",
        "    # 클래스별 이미지 파일 가져오기\n",
        "    images = [img for img in os.listdir(category_path) if img.lower().endswith(valid_extensions)]\n",
        "\n",
        "    # 이미지가 없으면 건너뜀\n",
        "    if len(images) == 0:\n",
        "        print(f\"'{category}' 폴더에 이미지가 없습니다. 건너뜁니다.\")\n",
        "        continue\n",
        "\n",
        "    # train/test로 분리\n",
        "    train_images, test_images = train_test_split(images, test_size=1 - split_ratio, random_state=42)\n",
        "\n",
        "    # 클래스별 train/test 디렉토리 생성\n",
        "    train_category_dir = os.path.join(train_dir, category)\n",
        "    test_category_dir = os.path.join(test_dir, category)\n",
        "    os.makedirs(train_category_dir, exist_ok=True)\n",
        "    os.makedirs(test_category_dir, exist_ok=True)\n",
        "\n",
        "    # train 이미지 이동\n",
        "    for img in train_images:\n",
        "        shutil.copy(os.path.join(category_path, img), os.path.join(train_category_dir, img))\n",
        "\n",
        "    # test 이미지 이동\n",
        "    for img in test_images:\n",
        "        shutil.copy(os.path.join(category_path, img), os.path.join(test_category_dir, img))\n",
        "\n",
        "    print(f\"'{category}' 클래스에서 Train: {len(train_images)}개, Test: {len(test_images)}개 파일이 이동되었습니다.\")\n",
        "\n",
        "print(\"Train/Test 데이터 분리가 완료되었습니다!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qc3oT8-t1FV",
        "outputId": "ffc23cc5-b7fc-4240-8c2a-e550b11a2250"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Straight' 클래스에서 Train: 388개, Test: 97개 파일이 이동되었습니다.\n",
            "'curly' 클래스에서 Train: 411개, Test: 103개 파일이 이동되었습니다.\n",
            "'kinky' 클래스에서 Train: 173개, Test: 44개 파일이 이동되었습니다.\n",
            "'Wavy' 클래스에서 Train: 263개, Test: 66개 파일이 이동되었습니다.\n",
            "'dreadlocks' 클래스에서 Train: 354개, Test: 89개 파일이 이동되었습니다.\n",
            "Train/Test 데이터 분리가 완료되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 데이터 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # DeiT 입력 크기\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# 데이터 로드\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "# DataLoader 생성\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "UQ3yXQ9nt4Xy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QFDSnCex8ag",
        "outputId": "1228f8f7-8daf-4cdd-ffa1-41e75e110633"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "TltF6JsKx-ps"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "FT_I6PW7syyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "VaPz1BITif2P",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66701e8-4b7a-4292-ceee-19e106891a66"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "import torchvision\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "NBXqPSMVo6Bp"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)"
      ],
      "metadata": {
        "id": "ve-9xpLdilnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12262c3-708b-41ff-f290-d95b3f8a47f9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.head = nn.Linear(model.head.in_features, 5)\n",
        "\n",
        "torch.nn.init.xavier_uniform_(model.head.weight)\n",
        "torch.nn.init.zeros_(model.head.bias)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmWysrgapoi4",
        "outputId": "664df14e-d825-4575-d62f-64eee150d43b",
        "collapsed": true
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VisionTransformer(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "    (norm): Identity()\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (patch_drop): Identity()\n",
            "  (norm_pre): Identity()\n",
            "  (blocks): Sequential(\n",
            "    (0): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (1): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (2): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (3): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (4): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (5): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (6): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (7): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (8): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (9): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (10): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (11): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (fc_norm): Identity()\n",
            "  (head_drop): Dropout(p=0.0, inplace=False)\n",
            "  (head): Linear(in_features=768, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = []\n",
        "test_labels = []  # 실제 레이블 저장\n",
        "predicted_labels = []  # 예측된 레이블 저장\n",
        "\n",
        "# 하위 폴더를 순회하며 이미지와 레이블을 로드\n",
        "try:\n",
        "    label_mapping = {label: idx for idx, label in enumerate(sorted(os.listdir(test_dir)))}\n",
        "    reverse_mapping = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "    for category in os.listdir(test_dir):\n",
        "        category_path = os.path.join(test_dir, category)\n",
        "        if not os.path.isdir(category_path):\n",
        "            continue\n",
        "\n",
        "        for file_name in os.listdir(category_path):\n",
        "            file_path = os.path.join(category_path, file_name)\n",
        "            if file_name.lower().endswith(valid_extensions):  # 유효한 이미지 파일인지 확인\n",
        "                try:\n",
        "                    # 폴더 이름을 레이블로 사용\n",
        "                    label = label_mapping[category]\n",
        "                    test_labels.append(label)\n",
        "\n",
        "                    # 이미지 열기 및 전처리\n",
        "                    img = Image.open(file_path).convert(\"RGB\")\n",
        "                    img_tensor = transform(img).unsqueeze(0).to(device)  # 배치 차원 추가\n",
        "\n",
        "                    # 모델 예측\n",
        "                    with torch.no_grad():\n",
        "                        output = model(img_tensor)\n",
        "                        predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "                    # 예측된 레이블 저장\n",
        "                    predicted_labels.append(predicted_class)\n",
        "                except Exception as e:\n",
        "                    print(f\"이미지 처리 실패: {file_name}, 오류: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"테스트 데이터 로드 중 오류 발생: {e}\")\n",
        "\n",
        "# 4. 정확도 계산 및 출력\n",
        "if test_labels and predicted_labels:\n",
        "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "    print(f\"테스트 데이터 개수: {len(test_labels)}\")\n",
        "    print(f\"정확도: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 예측 결과 예시 출력\n",
        "    for i in range(len(test_labels)):\n",
        "        true_label = reverse_mapping[test_labels[i]]\n",
        "        predicted_label = reverse_mapping[predicted_labels[i]]\n",
        "        print(f\"실제: {true_label} | 예측: {predicted_label}\")\n",
        "else:\n",
        "    print(\"테스트 데이터가 비어 있거나 예측 결과가 없습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_-l6KQ3w8yv",
        "outputId": "9a41906f-8fee-4807-e8eb-adb4bc816e1f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 개수: 399\n",
            "정확도: 24.31%\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Straight\n",
            "실제: Straight | 예측: dreadlocks\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: curly\n",
            "실제: Straight | 예측: kinky\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Wavy\n",
            "실제: Straight | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: Straight\n",
            "실제: curly | 예측: kinky\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: dreadlocks\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: curly\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Wavy\n",
            "실제: curly | 예측: Wavy\n",
            "실제: kinky | 예측: kinky\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: Wavy\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: Wavy\n",
            "실제: kinky | 예측: Wavy\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: curly\n",
            "실제: kinky | 예측: dreadlocks\n",
            "실제: kinky | 예측: Straight\n",
            "실제: kinky | 예측: curly\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: dreadlocks\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: dreadlocks\n",
            "실제: Wavy | 예측: dreadlocks\n",
            "실제: Wavy | 예측: dreadlocks\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: dreadlocks\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: dreadlocks\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: dreadlocks\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: dreadlocks\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: dreadlocks\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Straight\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: curly\n",
            "실제: Wavy | 예측: kinky\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: Wavy\n",
            "실제: Wavy | 예측: curly\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: kinky\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: dreadlocks\n",
            "실제: dreadlocks | 예측: Wavy\n",
            "실제: dreadlocks | 예측: curly\n",
            "실제: dreadlocks | 예측: Straight\n",
            "실제: dreadlocks | 예측: curly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning"
      ],
      "metadata": {
        "id": "GgmcvKXF3xoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "6GJ6GbUP3rzl"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습률 스케줄러 (옵션)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "19ozGpWi3fAV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10  # 에포크 수\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # 모델 학습 모드\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # 옵티마이저 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파 및 손실 계산\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 역전파 및 옵티마이저 업데이트\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실과 정확도 업데이트\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100.*correct/total:.2f}%\")\n",
        "\n",
        "    # 학습률 스케줄러 업데이트 (옵션)\n",
        "    scheduler.step()\n",
        "\n",
        "# 학습 완료\n",
        "print(\"Fine-Tuning 완료!\")"
      ],
      "metadata": {
        "id": "ZjB9_EWS3wy3",
        "outputId": "06b8fa24-5cd3-4c04-c25d-3bfe60596820",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5455, Accuracy: 79.17%\n",
            "Epoch [2/10], Loss: 0.1136, Accuracy: 96.10%\n",
            "Epoch [3/10], Loss: 0.0592, Accuracy: 98.17%\n",
            "Epoch [4/10], Loss: 0.0493, Accuracy: 98.30%\n",
            "Epoch [5/10], Loss: 0.0370, Accuracy: 98.99%\n",
            "Epoch [6/10], Loss: 0.0749, Accuracy: 97.73%\n",
            "Epoch [7/10], Loss: 0.0173, Accuracy: 99.37%\n",
            "Epoch [8/10], Loss: 0.0062, Accuracy: 99.81%\n",
            "Epoch [9/10], Loss: 0.0050, Accuracy: 99.81%\n",
            "Epoch [10/10], Loss: 0.0045, Accuracy: 99.81%\n",
            "Fine-Tuning 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 모드\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "print(f\"테스트 데이터 정확도: {100.*correct/total:.2f}%\")"
      ],
      "metadata": {
        "id": "qUF_gksW4Noi",
        "outputId": "395f8eea-3341-4145-ced3-3ac20a53cbd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 정확도: 92.46%\n"
          ]
        }
      ]
    }
  ]
}